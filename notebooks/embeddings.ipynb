{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/train_gr/game_overview.csv\n",
      "../data/train_gr/train.csv\n",
      "../data/test_gr/test.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('../data'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_set = pd.read_csv(\"../data/train_gr/train.csv\")\n",
    "test_set = pd.read_csv('../data/test_gr/test.csv')\n",
    "game_ov = pd.read_csv('../data/train_gr/game_overview.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping unrelevant features\n",
    "x = train_set[\"user_review\"]\n",
    "y = train_set[\"user_suggestion\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def cleanTexts(texts):\n",
    "    cleaned = []\n",
    "    pattern = \"[^a-zA-Z0-9]\"\n",
    "    for text in texts:\n",
    "        clrd = re.sub(pattern,\" \",text).lower().strip()\n",
    "        cleaned.append(clrd)\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i m scared and hearing creepy voices   so i ll pause for a moment and write a review while i wait for my heart beat to return to atleast somewhat calmer times   this game is adorable and creepy like my happy tree friends but with the graphics sceme of my childhood  but more bubble and  clean     hello 1990 s what charactes there are  that isnot trying to kill me  were likable and a bit odd   i did do a few noob things though  such as oh look a class room full of ghosts from dead children  lets shine my flashlight on them and stand there staring at them  or  hmm creepy music  i ll turn around and see if i can see what s chasing me never before in a game have i been this afraid of finding a locked door'"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_cleaned = cleanTexts(x)\n",
    "x_cleaned[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences \n",
    "from tensorflow.compat.v1.keras.layers import GRU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer \n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(x_cleaned)\n",
    "x_tokens = tokenizer.texts_to_sequences(x_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 127, 2012, 3, 3558, 3152, 3257, 29, 7, 151, 5595, 14, 4, 819, 3, 1082, 4, 182, 120, 7, 313, 14, 36, 1472, 1021, 2, 1765, 2, 1534, 1030, 13859, 213, 11, 5, 10, 3559, 3, 3152, 27, 36, 922, 610, 184, 15, 16, 1, 171, 16827, 9, 36, 3685, 15, 38, 10871, 3, 2579, 2923, 12072, 19, 63, 23043, 37, 17, 13, 23044, 267, 2, 244, 56, 179, 13860, 3, 4, 206, 2090, 7, 228, 57, 4, 137, 1766, 125, 189, 239, 26, 339, 232, 4, 299, 624, 281, 9, 5147, 44, 781, 2266, 846, 3616, 36, 3856, 20, 88, 3, 1045, 37, 5293, 39, 88, 33, 5596, 3152, 1001, 7, 151, 378, 175, 3, 119, 24, 7, 22, 119, 63, 19, 3506, 56, 173, 148, 12, 4, 5, 18, 7, 108, 11, 2612, 9, 1441, 4, 1138, 1875]\n"
     ]
    }
   ],
   "source": [
    "print(x_tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i m scared and hearing creepy voices   so i ll pause for a moment and write a review while i wait for my heart beat to return to atleast somewhat calmer times   this game is adorable and creepy like my happy tree friends but with the graphics sceme of my childhood  but more bubble and  clean     hello 1990 s what charactes there are  that isnot trying to kill me  were likable and a bit odd   i did do a few noob things though  such as oh look a class room full of ghosts from dead children  lets shine my flashlight on them and stand there staring at them  or  hmm creepy music  i ll turn around and see if i can see what s chasing me never before in a game have i been this afraid of finding a locked door\n"
     ]
    }
   ],
   "source": [
    "print(x_cleaned[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "len_arr = [len(s) for s in x_tokens]\n",
    "MAX_LEN = int(np.percentile(len_arr,.75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"maxlen.json\",mode=\"w\") as F:\n",
    "    json.dump({\"maxlen\":MAX_LEN},F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17494, 21)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tokens_pad = pad_sequences(x_tokens,maxlen=MAX_LEN)\n",
    "x_tokens_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_tokens_pad, np.asarray(y), test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = {} # Trained glove model \n",
    "with open(\"../embeddings/glove.6B.50d.txt\", encoding=\"UTF-8\") as f:\n",
    "    for line in f:\n",
    "        values = line.split() \n",
    "        word = values[0]\n",
    "        vec = np.asarray(values[1:],dtype=\"float32\")\n",
    "        word2vec[word] = vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing as uniform\n",
    "VOCAB_SIZE = len(tokenizer.word_index) + 1\n",
    "embedding_matrix = np.random.uniform(-1,1,(VOCAB_SIZE,50))\n",
    "\n",
    "for word,i in tokenizer.word_index.items():\n",
    "    if i < VOCAB_SIZE: \n",
    "        embedding_vector = word2vec.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each world will be 100D vector.\n",
    "VECTOR_SIZE = 50\n",
    "\n",
    "def buildModel(MAX_LEN,embedding_weights=None):\n",
    "    \n",
    "    model = keras.Sequential()\n",
    "    if embedding_weights is not None:\n",
    "        model.add(layers.Embedding(input_dim=VOCAB_SIZE,\n",
    "                                   output_dim=VECTOR_SIZE,\n",
    "                                   input_length=MAX_LEN,\n",
    "                                   weights=[embedding_weights],\n",
    "                                   trainable=True\n",
    "                              ))\n",
    "        \n",
    "    else:\n",
    "        model.add(layers.Embedding(input_dim=VOCAB_SIZE,\n",
    "                                   output_dim=VECTOR_SIZE,\n",
    "                                   input_length=MAX_LEN\n",
    "                                  ))\n",
    "    \n",
    "    model.add(GRU(10,return_sequences=False))\n",
    "    model.add(layers.Dense(1,activation=\"sigmoid\"))\n",
    "    \n",
    "    model.compile(optimizer='Adam',\n",
    "              loss='mse',\n",
    "              metrics=[keras.metrics.BinaryAccuracy(name=\"binary_accuracy\", dtype=None, threshold=0.5)])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, 21, 50)            2596450   \n",
      "_________________________________________________________________\n",
      "gru_18 (GRU)                 (None, 10)                1830      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 2,598,291\n",
      "Trainable params: 2,598,291\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = buildModel(MAX_LEN,embedding_matrix)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "350/350 [==============================] - 11s 33ms/step - loss: 0.1020 - binary_accuracy: 0.8659 - val_loss: 0.1747 - val_binary_accuracy: 0.7496\n",
      "Epoch 2/10\n",
      "350/350 [==============================] - 12s 33ms/step - loss: 0.0747 - binary_accuracy: 0.9082 - val_loss: 0.1829 - val_binary_accuracy: 0.7345\n",
      "Epoch 3/10\n",
      "350/350 [==============================] - 11s 32ms/step - loss: 0.0548 - binary_accuracy: 0.9351 - val_loss: 0.1952 - val_binary_accuracy: 0.7267\n",
      "Epoch 4/10\n",
      "350/350 [==============================] - 11s 33ms/step - loss: 0.0399 - binary_accuracy: 0.9556 - val_loss: 0.2034 - val_binary_accuracy: 0.7331\n",
      "Epoch 5/10\n",
      "350/350 [==============================] - 11s 32ms/step - loss: 0.0298 - binary_accuracy: 0.9677 - val_loss: 0.2115 - val_binary_accuracy: 0.7274\n",
      "Epoch 6/10\n",
      "350/350 [==============================] - 11s 32ms/step - loss: 0.0225 - binary_accuracy: 0.9766 - val_loss: 0.2150 - val_binary_accuracy: 0.7292\n",
      "Epoch 7/10\n",
      "350/350 [==============================] - 12s 33ms/step - loss: 0.0181 - binary_accuracy: 0.9818 - val_loss: 0.2284 - val_binary_accuracy: 0.7274\n",
      "Epoch 8/10\n",
      "350/350 [==============================] - 12s 35ms/step - loss: 0.0144 - binary_accuracy: 0.9852 - val_loss: 0.2314 - val_binary_accuracy: 0.7263\n",
      "Epoch 9/10\n",
      "350/350 [==============================] - 12s 33ms/step - loss: 0.0125 - binary_accuracy: 0.9872 - val_loss: 0.2328 - val_binary_accuracy: 0.7242\n",
      "Epoch 10/10\n",
      "350/350 [==============================] - 12s 33ms/step - loss: 0.0117 - binary_accuracy: 0.9879 - val_loss: 0.2357 - val_binary_accuracy: 0.7256\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f86d9cb6700>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 0s 3ms/step - loss: 0.2414 - binary_accuracy: 0.7199\n",
      "0.7199199795722961\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "\n",
    "_, acc = model.evaluate(x_test, y_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-17 16:49:51.029541: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: embedding_sentiments/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('embedding_sentiments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm scared and hearing creepy voices.  So I'll pause for a moment and write a review while I wait for my heart beat to return to atleast somewhat calmer times.  This game is adorable and creepy like my happy tree friends but with the graphics sceme of my childhood (but more bubble and 'clean').  Hello 1990's.What charactes there are (that isnot trying to kill me) were likable and a bit odd.  I did do a few noob things though, such as:Oh look a class room full of ghosts from dead children, lets shine my flashlight on them and stand there staring at them..Or, hmm creepy music, I'll turn around and see if I can see what's chasing me.Never before in a game have I been this afraid of finding a locked door.\n",
      "i m scared and hearing creepy voices   so i ll pause for a moment and write a review while i wait for my heart beat to return to atleast somewhat calmer times   this game is adorable and creepy like my happy tree friends but with the graphics sceme of my childhood  but more bubble and  clean     hello 1990 s what charactes there are  that isnot trying to kill me  were likable and a bit odd   i did do a few noob things though  such as oh look a class room full of ghosts from dead children  lets shine my flashlight on them and stand there staring at them  or  hmm creepy music  i ll turn around and see if i can see what s chasing me never before in a game have i been this afraid of finding a locked door\n",
      "[7, 127, 2012, 3, 3558, 3152, 3257, 29, 7, 151, 5595, 14, 4, 819, 3, 1082, 4, 182, 120, 7, 313, 14, 36, 1472, 1021, 2, 1765, 2, 1534, 1030, 13859, 213, 11, 5, 10, 3559, 3, 3152, 27, 36, 922, 610, 184, 15, 16, 1, 171, 16827, 9, 36, 3685, 15, 38, 10871, 3, 2579, 2923, 12072, 19, 63, 23043, 37, 17, 13, 23044, 267, 2, 244, 56, 179, 13860, 3, 4, 206, 2090, 7, 228, 57, 4, 137, 1766, 125, 189, 239, 26, 339, 232, 4, 299, 624, 281, 9, 5147, 44, 781, 2266, 846, 3616, 36, 3856, 20, 88, 3, 1045, 37, 5293, 39, 88, 33, 5596, 3152, 1001, 7, 151, 378, 175, 3, 119, 24, 7, 22, 119, 63, 19, 3506, 56, 173, 148, 12, 4, 5, 18, 7, 108, 11, 2612, 9, 1441, 4, 1138, 1875]\n",
      "[[  22  119   63   19 3506   56  173  148   12    4    5   18    7  108\n",
      "    11 2612    9 1441    4 1138 1875]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 10), dtype=float32, numpy=\n",
       "array([[-0.3324464 , -0.966098  ,  0.93294835,  0.3458986 ,  0.1472227 ,\n",
       "        -0.5522215 ,  0.6037281 , -0.8544234 , -0.38403505,  0.3401982 ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_extractor = keras.Model(\n",
    "    inputs=model.inputs,\n",
    "    outputs=[layer.output for layer in model.layers],\n",
    ")\n",
    "print(x[0])\n",
    "print(x_cleaned[0]) \n",
    "print(x_tokens[0])\n",
    "print(pad_sequences([x_tokens[0]],maxlen=MAX_LEN))\n",
    "feature_extractor(pad_sequences([x_tokens[0]],maxlen=MAX_LEN).reshape(1,21))[1] # requested embbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"../../gre-scraper/data/reviews.json\", 'r') as f:\n",
    "    reviews = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_reviews_cleaned = {}\n",
    "for idx in reviews.keys():\n",
    "    scraped_reviews_cleaned[idx] = []\n",
    "    for review in reviews[idx]:\n",
    "        scraped_reviews_cleaned[idx].append(cleanTexts([review[\"Review\"]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tokens_scraped = tokenizer.texts_to_sequences(scraped_reviews_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x_tokens_scraped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[92],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [15500],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [10278],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [15717],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [2526],\n",
       " [3596],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [7323],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [10641],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [35630],\n",
       " [],\n",
       " [],\n",
       " [1334],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [10048],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [20154],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [1312],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " []]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tokens_scraped"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gre-embedding-system",
   "language": "python",
   "name": "gre-embedding-system"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
