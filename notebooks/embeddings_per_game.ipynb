{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8d4c564",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences \n",
    "from tensorflow.compat.v1.keras.layers import GRU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73e4d305",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('./embedding_sentiments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcdb4014",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_set = pd.read_csv(\"../data/train_gr/train.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b3aeb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def cleanTexts(texts):\n",
    "    cleaned = []\n",
    "    pattern = \"[^a-zA-Z0-9]\"\n",
    "    for text in texts:\n",
    "        clrd = re.sub(pattern,\" \",text).lower().strip()\n",
    "        cleaned.append(clrd)\n",
    "    return cleaned\n",
    "\n",
    "x = train_set[\"user_review\"]\n",
    "x_cleaned = cleanTexts(x)\n",
    "\n",
    "# Tokenizer \n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(x_cleaned)\n",
    "x_tokens = tokenizer.texts_to_sequences(x_cleaned)\n",
    "\n",
    "import json\n",
    "with open(\"maxlen.json\",mode=\"r\") as F:\n",
    "    maxlen = json.load(F)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84789bd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17494, 21)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pad Tokenised sequences\n",
    "x_tokens_pad = pad_sequences(x_tokens,maxlen=maxlen[\"maxlen\"])\n",
    "x_tokens_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca80dd80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm scared and hearing creepy voices.  So I'll pause for a moment and write a review while I wait for my heart beat to return to atleast somewhat calmer times.  This game is adorable and creepy like my happy tree friends but with the graphics sceme of my childhood (but more bubble and 'clean').  Hello 1990's.What charactes there are (that isnot trying to kill me) were likable and a bit odd.  I did do a few noob things though, such as:Oh look a class room full of ghosts from dead children, lets shine my flashlight on them and stand there staring at them..Or, hmm creepy music, I'll turn around and see if I can see what's chasing me.Never before in a game have I been this afraid of finding a locked door.\n",
      "i m scared and hearing creepy voices   so i ll pause for a moment and write a review while i wait for my heart beat to return to atleast somewhat calmer times   this game is adorable and creepy like my happy tree friends but with the graphics sceme of my childhood  but more bubble and  clean     hello 1990 s what charactes there are  that isnot trying to kill me  were likable and a bit odd   i did do a few noob things though  such as oh look a class room full of ghosts from dead children  lets shine my flashlight on them and stand there staring at them  or  hmm creepy music  i ll turn around and see if i can see what s chasing me never before in a game have i been this afraid of finding a locked door\n",
      "[7, 127, 2012, 3, 3558, 3152, 3257, 29, 7, 151, 5595, 14, 4, 819, 3, 1082, 4, 182, 120, 7, 313, 14, 36, 1472, 1021, 2, 1765, 2, 1534, 1030, 13859, 213, 11, 5, 10, 3559, 3, 3152, 27, 36, 922, 610, 184, 15, 16, 1, 171, 16827, 9, 36, 3685, 15, 38, 10871, 3, 2579, 2923, 12072, 19, 63, 23043, 37, 17, 13, 23044, 267, 2, 244, 56, 179, 13860, 3, 4, 206, 2090, 7, 228, 57, 4, 137, 1766, 125, 189, 239, 26, 339, 232, 4, 299, 624, 281, 9, 5147, 44, 781, 2266, 846, 3616, 36, 3856, 20, 88, 3, 1045, 37, 5293, 39, 88, 33, 5596, 3152, 1001, 7, 151, 378, 175, 3, 119, 24, 7, 22, 119, 63, 19, 3506, 56, 173, 148, 12, 4, 5, 18, 7, 108, 11, 2612, 9, 1441, 4, 1138, 1875]\n",
      "[[  22  119   63   19 3506   56  173  148   12    4    5   18    7  108\n",
      "    11 2612    9 1441    4 1138 1875]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 10), dtype=float32, numpy=\n",
       "array([[-0.3324464 , -0.966098  ,  0.93294835,  0.3458986 ,  0.1472227 ,\n",
       "        -0.5522215 ,  0.6037281 , -0.8544234 , -0.38403505,  0.3401982 ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_extractor = keras.Model(\n",
    "    inputs=model.inputs,\n",
    "    outputs=[layer.output for layer in model.layers],\n",
    ")\n",
    "print(x[0])\n",
    "print(x_cleaned[0]) \n",
    "print(x_tokens[0])\n",
    "print(pad_sequences([x_tokens[0]],maxlen=maxlen[\"maxlen\"]))\n",
    "feature_extractor(pad_sequences([x_tokens[0]],maxlen=maxlen[\"maxlen\"]).reshape(1,21))[1] # requested embbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e6b0c33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(17494, 10), dtype=float32, numpy=\n",
       "array([[-0.3324464 , -0.9660979 ,  0.93294835, ..., -0.85442346,\n",
       "        -0.38403505,  0.34019822],\n",
       "       [ 0.27616048, -0.897205  ,  0.21370235, ..., -0.56942254,\n",
       "        -0.29262242,  0.6775218 ],\n",
       "       [-0.61817336, -0.9802528 ,  0.9786215 , ..., -0.9246477 ,\n",
       "         0.46472743,  0.7306475 ],\n",
       "       ...,\n",
       "       [ 0.2377021 ,  0.92442423, -0.6943325 , ...,  0.85971653,\n",
       "        -0.7256061 , -0.40463376],\n",
       "       [ 0.519196  ,  0.02329798, -0.29234242, ..., -0.15798683,\n",
       "        -0.24509442, -0.2130076 ],\n",
       "       [-0.7072564 , -0.99768126,  0.98328817, ..., -0.9862137 ,\n",
       "        -0.31048873,  0.7591829 ]], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_extractor(x_tokens_pad)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6ae5e8ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.3324464 , -0.9660979 ,  0.93294835, ..., -0.85442346,\n",
       "        -0.38403505,  0.34019822],\n",
       "       [ 0.27616048, -0.897205  ,  0.21370235, ..., -0.56942254,\n",
       "        -0.29262242,  0.6775218 ],\n",
       "       [-0.61817336, -0.9802528 ,  0.9786215 , ..., -0.9246477 ,\n",
       "         0.46472743,  0.7306475 ],\n",
       "       ...,\n",
       "       [ 0.2377021 ,  0.92442423, -0.6943325 , ...,  0.85971653,\n",
       "        -0.7256061 , -0.40463376],\n",
       "       [ 0.519196  ,  0.02329798, -0.29234242, ..., -0.15798683,\n",
       "        -0.24509442, -0.2130076 ],\n",
       "       [-0.7072564 , -0.99768126,  0.98328817, ..., -0.9862137 ,\n",
       "        -0.31048873,  0.7591829 ]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.squeeze(feature_extractor(x_tokens_pad)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e0031db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds = np.squeeze(feature_extractor(x_tokens_pad)[1])\n",
    "for i in range(embeds.shape[1]):\n",
    "    train_set[\"embedding{}\".format(i)] = embeds[:,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "50adffd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_mean = train_set.groupby([\"title\"]).mean()[[\"embedding0\",\"embedding1\",\"embedding2\",\"embedding3\",\"embedding4\",\"embedding5\",\"embedding6\",\"embedding7\",\"embedding8\",\"embedding9\"]]\n",
    "embedded_sum = train_set.groupby([\"title\"]).sum()[[\"embedding0\",\"embedding1\",\"embedding2\",\"embedding3\",\"embedding4\",\"embedding5\",\"embedding6\",\"embedding7\",\"embedding8\",\"embedding9\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f8a8beb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_mean.to_csv(\"embeddings_per_game_mean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "06c6540d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_sum.to_csv(\"embeddings_per_game_sum.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6372645a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gre-embedding-system",
   "language": "python",
   "name": "gre-embedding-system"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
